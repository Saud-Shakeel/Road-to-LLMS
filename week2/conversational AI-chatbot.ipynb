{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dd0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eac2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-'):\n",
    "    print('API Key exists, good to go.')\n",
    "else:\n",
    "    print('API Key doesnt exist, troubleshoot the problem!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfcf031",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()\n",
    "\n",
    "system_prompt = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
    "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
    "For example, if the customer says 'I'm looking to buy a hat', \\\n",
    "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'\\\n",
    "Encourage the customer to buy hats if they are unsure what to get. \\\n",
    "If the customer asks for shoes, you should respond that shoes are not on sale today, but remind the customer to look at hats!\\\n",
    "The store does not sell belts; if you are asked for belts, be sure to point out other items on sale.\\\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177dd22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamed_response_from_AI_assistant(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd1bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn = streamed_response_from_AI_assistant , type = \"messages\").launch(share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9a5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
