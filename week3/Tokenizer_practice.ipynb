{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rIiBow_Dmzo2"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from transformers import AutoTokenizer\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "UwAmrb3CnTr4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "microsoft_tokenizer = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "qwen_tokenizer = \"Qwen/Qwen3-0.6B\"\n",
        "starcoder_tokenizer = \"bigcode/starcoder2-3b\"\n",
        "llama_tokenizer = \"meta-llama/Llama-3.1-8B\""
      ],
      "metadata": {
        "id": "Zajd80bS1M34"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
        "    {'role': 'user', 'content': 'Tell a light-hearted joke related to Data Scientists.'}\n",
        "]"
      ],
      "metadata": {
        "id": "w0ANnylG8ypO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(llama_tokenizer, trust_remote_code=True)\n",
        "\n",
        "text = \"I am excited to show tokenizer in action. Let's start.\"\n",
        "\n",
        "tokens = tokenizer.encode(text)\n",
        "\n",
        "print(tokens)\n",
        "print()\n",
        "\n",
        "print(tokenizer.batch_decode(tokens))\n",
        "print()\n",
        "\n",
        "for token_id in tokens:\n",
        "  print(f\"{token_id} = {tokenizer.decode(token_id)}\")\n",
        "\n",
        "print()\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "yzemJH_YnoAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(starcoder_tokenizer)\n",
        "\n",
        "code = \"\"\"\n",
        "def hello_world():\n",
        "    print(\"Hello, world!\")\n",
        "\"\"\"\n",
        "\n",
        "tokens = tokenizer.encode(code)\n",
        "\n",
        "print(tokens)\n",
        "print()\n",
        "\n",
        "print(tokenizer.batch_decode(tokens))\n",
        "print()\n",
        "\n",
        "for token_id in tokens:\n",
        "  print(f\"{token_id} = {tokenizer.decode(token_id)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-cTSVNUu7zO",
        "outputId": "75fc2de9-4e80-41a3-ecaf-c7c2f1a65ed2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[222, 610, 17966, 100, 5879, 2284, 303, 1489, 459, 8302, 49, 5810, 16013, 222]\n",
            "\n",
            "['\\n', 'def', ' hello', '_', 'world', '():', '\\n   ', ' print', '(\"', 'Hello', ',', ' world', '!\")', '\\n']\n",
            "\n",
            "222 = \n",
            "\n",
            "610 = def\n",
            "17966 =  hello\n",
            "100 = _\n",
            "5879 = world\n",
            "2284 = ():\n",
            "303 = \n",
            "   \n",
            "1489 =  print\n",
            "459 = (\"\n",
            "8302 = Hello\n",
            "49 = ,\n",
            "5810 =  world\n",
            "16013 = !\")\n",
            "222 = \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(qwen_tokenizer, trust_remote_code=True)\n",
        "\n",
        "text = \"I am excited to show tokenizer in action. Let's start.\"\n",
        "\n",
        "tokens = tokenizer.encode(text)\n",
        "\n",
        "print(tokens)\n",
        "print()\n",
        "\n",
        "print(tokenizer.decode(tokens))\n",
        "print()\n",
        "\n",
        "\n",
        "print(tokenizer.batch_decode(tokens))\n",
        "print()\n",
        "\n",
        "for token_id in tokens:\n",
        "  print(f\"{token_id} = {tokenizer.decode(token_id)}\")\n",
        "\n",
        "print()\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXBOic9f2JPe",
        "outputId": "7cd75a09-e39b-4770-a0c0-cdbd4d43ea29"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[40, 1079, 12035, 311, 1473, 45958, 304, 1917, 13, 6771, 594, 1191, 13]\n",
            "\n",
            "I am excited to show tokenizer in action. Let's start.\n",
            "\n",
            "['I', ' am', ' excited', ' to', ' show', ' tokenizer', ' in', ' action', '.', ' Let', \"'s\", ' start', '.']\n",
            "\n",
            "40 = I\n",
            "1079 =  am\n",
            "12035 =  excited\n",
            "311 =  to\n",
            "1473 =  show\n",
            "45958 =  tokenizer\n",
            "304 =  in\n",
            "1917 =  action\n",
            "13 = .\n",
            "6771 =  Let\n",
            "594 = 's\n",
            "1191 =  start\n",
            "13 = .\n",
            "\n",
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "Tell a light-hearted joke related to Data Scientists.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(microsoft_tokenizer, trust_remote_code=True)\n",
        "\n",
        "text = \"I am excited to show tokenizer in action. Let's start.\"\n",
        "\n",
        "tokens = tokenizer.encode(text)\n",
        "\n",
        "print(tokens)\n",
        "print()\n",
        "\n",
        "print(tokenizer.decode(tokens))\n",
        "print()\n",
        "\n",
        "\n",
        "print(tokenizer.batch_decode(tokens))\n",
        "print()\n",
        "\n",
        "for token_id in tokens:\n",
        "  print(f\"{token_id} = {tokenizer.decode(token_id)}\")\n",
        "\n",
        "print()\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdFjp1RF5yfR",
        "outputId": "d3490600-ba89-4cd3-b71b-2f0a9df92280"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[306, 626, 24173, 304, 1510, 5993, 3950, 297, 3158, 29889, 2803, 29915, 29879, 1369, 29889]\n",
            "\n",
            "I am excited to show tokenizer in action. Let's start.\n",
            "\n",
            "['I', 'am', 'excited', 'to', 'show', 'token', 'izer', 'in', 'action', '.', 'Let', \"'\", 's', 'start', '.']\n",
            "\n",
            "306 = I\n",
            "626 = am\n",
            "24173 = excited\n",
            "304 = to\n",
            "1510 = show\n",
            "5993 = token\n",
            "3950 = izer\n",
            "297 = in\n",
            "3158 = action\n",
            "29889 = .\n",
            "2803 = Let\n",
            "29915 = '\n",
            "29879 = s\n",
            "1369 = start\n",
            "29889 = .\n",
            "\n",
            "<|system|>\n",
            "You are a helpful assistant.<|end|>\n",
            "<|user|>\n",
            "Tell a light-hearted joke related to Data Scientists.<|end|>\n",
            "<|assistant|>\n",
            "\n"
          ]
        }
      ]
    }
  ]
}